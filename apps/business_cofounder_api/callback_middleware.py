"""Middleware for LLM-driven callback mechanism.

This middleware provides a callback tool that the LLM can use to send intermediate
and final results to a callback URL. The LLM decides when to send callbacks.
"""

from collections.abc import Awaitable, Callable
from datetime import datetime
from typing import Any, Annotated, NotRequired, TypedDict, cast

from langchain.agents.middleware.types import (
    AgentMiddleware,
    AgentState,
    ModelRequest,
    ModelResponse,
)
from langchain.tools import InjectedToolCallId, ToolRuntime
from langchain_core.messages import ToolMessage
from langchain_core.tools import StructuredTool
from langgraph.runtime import Runtime
from langgraph.types import Command


class CallbackState(AgentState):
    """State for callback configuration."""

    callback_url: NotRequired[str | None]
    """The callback URL to POST updates to."""

    session_id: NotRequired[str | None]
    """The session ID (thread_id) for this conversation."""


CALLBACK_TOOL_DESCRIPTION = """Send a callback to deliver intermediate or final results to the user.

Use this tool when you have:
- An intermediate result or conclusion that should be communicated to the user
- A final conclusion or answer
- An artifact generated by applying a skill (e.g., a document, analysis, or output)

The callback will be sent to the configured callback URL with the session ID, your message/status, and a timestamp.

Args:
    message: The actual message content to send to the user (for assistant responses).
        Use this when you have substantive content to deliver.
    status: A status update or progress notification (for non-message updates like tool calls,
        processing states, etc.). Use this for status updates that are not direct user messages.

Note: You should use EITHER 'message' OR 'status', not both. Use 'message' for actual content
you want to show the user, and 'status' for progress/state updates.
"""


CALLBACK_SYSTEM_PROMPT = """## Callback Mechanism

You have access to a `callback` tool that allows you to send intermediate and final results to the user via a callback URL.

**When to use callbacks:**

1. **Intermediate results**: When you have meaningful intermediate findings or conclusions that should be shared with the user
   - Example: After completing a significant analysis step
   - Example: When you've identified key information that answers part of the user's question

2. **Intermediate conclusions**: When you reach a milestone or checkpoint in your work
   - Example: After successfully applying a skill and generating an artifact
   - Example: When you complete a major phase of work

3. **Final conclusions**: When you have the complete answer or result
   - Example: After fully answering the user's question
   - Example: After completing all requested work

4. **Artifacts**: When you generate deliverables (documents, files, analysis results, etc.)
   - Example: After creating a document using write_file
   - Example: After generating a comprehensive analysis or report

**How to use the callback tool:**

- Use the `message` parameter for actual content you want to deliver to the user
- Use the `status` parameter for progress updates, tool call notifications, or processing states
- Use callbacks strategically to keep the user informed of progress without overwhelming them with every minor step
- For final responses, always send a callback with the complete message before concluding"""


def _get_callback_tool() -> StructuredTool:
    """Create the callback tool."""
    
    def sync_callback(
        message: Annotated[
            str | None,
            "The actual message content to send to the user (for assistant responses).",
        ] = None,
        status: Annotated[
            str | None,
            "A status update or progress notification (for non-message updates).",
        ] = None,
        runtime: ToolRuntime[None, CallbackState] = None,  # type: ignore[assignment]
        tool_call_id: Annotated[str, InjectedToolCallId] = "",
    ) -> Command:
        """Send a callback to deliver results to the user.
        
        Args:
            message: The actual message content (use for assistant responses).
            status: A status update (use for progress/state updates).
            runtime: Runtime context for accessing state (automatically injected).
            tool_call_id: Injected tool call ID.
        
        Returns:
            Command that triggers the callback and returns a tool message.
        """
        # Get callback_url and session_id from state
        state = runtime.state if runtime else {}
        callback_url = state.get("callback_url")
        session_id = state.get("session_id")
        
        if not callback_url:
            return Command(
                update={
                    "messages": [
                        ToolMessage(
                            content="Callback URL not configured. Cannot send callback.",
                            tool_call_id=tool_call_id,
                        )
                    ]
                }
            )
        
        if not message and not status:
            return Command(
                update={
                    "messages": [
                        ToolMessage(
                            content="Either 'message' or 'status' must be provided for callback.",
                            tool_call_id=tool_call_id,
                        )
                    ]
                }
            )
        
        # Generate timestamp
        timestamp = datetime.utcnow().isoformat() + "Z"
        
        # Build callback payload
        callback_payload: dict[str, Any] = {
            "session_id": session_id,
            "timestamp": timestamp,
        }
        
        if message:
            callback_payload["message"] = message
        if status:
            callback_payload["status"] = status
        
        # Invoke callback asynchronously (fire and forget)
        try:
            import requests
            requests.post(
                callback_url,
                json=callback_payload,
                headers={"Content-Type": "application/json"},
                timeout=30,
            )
        except Exception as e:  # noqa: BLE001
            # Log error but don't fail the tool call
            import logging
            logger = logging.getLogger(__name__)
            logger.warning("Failed to invoke callback URL %s: %s", callback_url, str(e))
            return Command(
                update={
                    "messages": [
                        ToolMessage(
                            content=f"Callback failed: {str(e)}",
                            tool_call_id=tool_call_id,
                        )
                    ]
                }
            )
        
        # Return success message
        callback_type = "message" if message else "status"
        callback_value = message if message else status
        return Command(
            update={
                "messages": [
                    ToolMessage(
                        content=f"Callback sent ({callback_type}): {callback_value[:100]}...",
                        tool_call_id=tool_call_id,
                    )
                ]
            }
        )
    
    async def async_callback(
        message: Annotated[
            str | None,
            "The actual message content to send to the user (for assistant responses).",
        ] = None,
        status: Annotated[
            str | None,
            "A status update or progress notification (for non-message updates).",
        ] = None,
        runtime: ToolRuntime[None, CallbackState] = None,  # type: ignore[assignment]
        tool_call_id: Annotated[str, InjectedToolCallId] = "",
    ) -> Command:
        """Async version of callback tool."""
        # Same implementation as sync version
        return sync_callback(message, status, runtime, tool_call_id)
    
    return StructuredTool.from_function(
        func=sync_callback,
        coroutine=async_callback,
        name="callback",
        description=CALLBACK_TOOL_DESCRIPTION,
    )


class CallbackMiddleware(AgentMiddleware):
    """Middleware for LLM-driven callback mechanism.
    
    This middleware:
    1. Stores callback_url and session_id (thread_id) in agent state
    2. Provides a callback tool that the LLM can call to send updates
    3. Adds system prompt instructions about when and how to use callbacks
    
    Example:
        ```python
        from apps.business_cofounder_api.callback_middleware import CallbackMiddleware
        
        agent = create_agent(
            model="anthropic:claude-sonnet-4-20250514",
            middleware=[CallbackMiddleware()],
        )
        ```
    """
    
    state_schema = CallbackState
    
    def __init__(self) -> None:
        """Initialize the CallbackMiddleware."""
        self.tools = [_get_callback_tool()]
    
    def before_agent(
        self,
        state: CallbackState,
        runtime: Runtime,
    ) -> dict[str, Any] | None:
        """Initialize callback state from runtime config and initial state.
        
        Args:
            state: Current agent state (may already have callback_url from initial_state).
            runtime: Runtime context.
        
        Returns:
            Updated state with session_id (thread_id) if not present.
            Note: callback_url is expected to be set in initial_state by the caller.
        """
        updates: dict[str, Any] = {}
        
        # Extract thread_id from config and set as session_id
        config = runtime.config if hasattr(runtime, "config") else {}
        configurable = config.get("configurable", {})
        thread_id = configurable.get("thread_id")
        
        if thread_id and "session_id" not in state:
            updates["session_id"] = thread_id
        
        # callback_url should be set in initial_state when invoking the agent
        # We preserve it if it exists, but don't set it here if missing (let caller handle it)
        
        return updates if updates else None
    
    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        """Inject callback instructions into the system prompt.
        
        This runs on every model call to ensure callback guidance is always available.
        Only adds instructions if callback_url is configured.
        
        Args:
            request: The model request being processed.
            handler: The handler function to call with the modified request.
        
        Returns:
            The model response from the handler.
        """
        # Check if callback_url is configured
        state = cast(CallbackState, request.state)
        callback_url = state.get("callback_url")
        
        # Only add system prompt if callback_url is configured
        if callback_url:
            system_prompt = request.system_prompt + "\n\n" + CALLBACK_SYSTEM_PROMPT if request.system_prompt else CALLBACK_SYSTEM_PROMPT
            return handler(request.override(system_prompt=system_prompt))
        
        return handler(request)
    
    async def awrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], Awaitable[ModelResponse]],
    ) -> ModelResponse:
        """Async version of wrap_model_call.
        
        Args:
            request: The model request being processed.
            handler: The handler function to call with the modified request.
        
        Returns:
            The model response from the handler.
        """
        state = cast(CallbackState, request.state)
        callback_url = state.get("callback_url")
        
        if callback_url:
            system_prompt = request.system_prompt + "\n\n" + CALLBACK_SYSTEM_PROMPT if request.system_prompt else CALLBACK_SYSTEM_PROMPT
            return await handler(request.override(system_prompt=system_prompt))
        
        return await handler(request)

