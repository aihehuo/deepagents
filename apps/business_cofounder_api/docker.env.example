# Copy to .docker.env and fill values.

# ============================================================================
# Model Provider Configuration
# ============================================================================

# Supported model providers (comma-separated list)
# Examples: "qwen", "deepseek", "qwen,deepseek"
# Default: both qwen and deepseek are supported
SUPPORTED_MODEL_PROVIDERS=qwen,deepseek

# ============================================================================
# Provider-Specific Configuration
# ============================================================================

# ---- Qwen Provider Configuration
# Base URL for Qwen API (DashScope compatible-mode)
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# API key for Qwen
QWEN_API_KEY=your_qwen_api_key_here
# Optional: Provider-specific overrides (defaults to shared MODEL_API_* vars)
# QWEN_MAX_TOKENS=20000
# QWEN_TIMEOUT_S=180.0
# QWEN_TEMPERATURE=0.2

# ---- DeepSeek Provider Configuration
# Base URL for DeepSeek API (Anthropic-compatible)
DEEPSEEK_BASE_URL=https://api.deepseek.com/anthropic
# API key for DeepSeek
DEEPSEEK_API_KEY=your_deepseek_api_key_here
# Optional: Provider-specific overrides (defaults to shared MODEL_API_* vars)
# DEEPSEEK_MAX_TOKENS=20000
# DEEPSEEK_TIMEOUT_S=180.0
# DEEPSEEK_TEMPERATURE=0.2

# ============================================================================
# Model Names (Provider-Specific)
# ============================================================================

# Main agent model names (provider-specific)
# Examples: "qwen-plus", "qwen-max", "deepseek-chat", "deepseek-reasoner"
QWEN_MAIN_AGENT_MODEL=qwen-plus
DEEPSEEK_MAIN_AGENT_MODEL=deepseek-chat

# Coder subagent model names (optional; uses same provider config as main agent)
# Examples: "qwen-coder-plus", "qwen3-coder-flash", "deepseek-coder"
QWEN_CODER_SUBAGENT_MODEL=qwen3-coder-flash
# DEEPSEEK_CODER_SUBAGENT_MODEL=deepseek-coder

# AI He Huo subagent model names (optional; uses same provider config as main agent)
# Examples: "qwen-plus", "qwen-max"
# QWEN_AIHEHUO_SUBAGENT_MODEL=qwen-plus
# DEEPSEEK_AIHEHUO_SUBAGENT_MODEL=deepseek-chat

# ============================================================================
# API Configuration
# ============================================================================

# ---- Logging
BC_API_LOG_CHAT_IO=1
BC_API_LOG_TRUNCATE_CHARS=2000

# ---- Debug/Development Options
# BC_API_STREAM_DEBUG=1
# BC_API_ENABLE_STATE_ENDPOINT=1
# BC_API_OPENAI_NO_THREAD=1
# BC_API_ASYNCIO_EXECUTOR_WORKERS=1
# BC_API_DISABLE_CHECKPOINT_EXECUTOR=1

# ============================================================================
# AI He Huo Platform Integration
# ============================================================================

# API key for AI He Huo platform (required for AI He Huo subagent search functionality)
AIHEHUO_API_KEY=your_aihehuo_api_key_here

# Base URL for AI He Huo API (optional, defaults to https://new-api.aihehuo.com)
AIHEHUO_API_BASE=https://new-api.aihehuo.com

# ============================================================================
# Provider Selection Notes
# ============================================================================
# When multiple providers are configured (as shown above), the system will:
# - Auto-detect which provider to use based on SUPPORTED_MODEL_PROVIDERS
# - If only one provider is listed, that provider will be used by default
# - You can also explicitly specify provider when calling parse_model_config()
# 
# To use only one provider, set SUPPORTED_MODEL_PROVIDERS to a single value:
# SUPPORTED_MODEL_PROVIDERS=qwen
# or
# SUPPORTED_MODEL_PROVIDERS=deepseek
